{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppereiracampoverde/Advanced-Topics-in-Data-Analysis-Big-Data-Data-Mining-Cloud-Computing/blob/main/Text_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d67ea91",
      "metadata": {
        "id": "1d67ea91"
      },
      "source": [
        "## Text Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "42ac0d30",
      "metadata": {
        "id": "42ac0d30",
        "outputId": "d35073c6-ccce-41cd-e1a1-9d3c5e122de9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b6fa20be",
      "metadata": {
        "id": "b6fa20be",
        "outputId": "af747fe1-80dd-43af-d9cb-573bcdb061c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'Big', 'Data', 'course', 'in', 'CCTB', '.']\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "text = \"This is a Big Data course in CCTB.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33b58e3a",
      "metadata": {
        "id": "33b58e3a",
        "outputId": "e45223de-8173-4117-bc3e-d2ff56b4fd98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'This': 1, 'is': 1, 'a': 1, 'Big': 1, 'Data': 1, 'course': 1, 'in': 1, 'CCTB': 1, '.': 1})\n"
          ]
        }
      ],
      "source": [
        "# Counter Tokens\n",
        "from collections import Counter\n",
        "\n",
        "word_counts = Counter(tokens)\n",
        "print(word_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6e2b3da5",
      "metadata": {
        "id": "6e2b3da5",
        "outputId": "136445f1-bfc2-4a46-d32f-bd0f326b2abc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Big', 'Data', 'course', 'CCTB', '.']\n"
          ]
        }
      ],
      "source": [
        "# StopWords (The, an , or ,etc.)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db2358b1",
      "metadata": {
        "id": "db2358b1",
        "outputId": "3d97834f-ed0f-44a3-e012-6312d03a4678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thi', 'is', 'a', 'big', 'data', 'cours', 'in', 'cctb', '.']\n",
            "['This', 'is', 'a', 'Big', 'Data', 'course', 'in', 'CCTB', '.']\n"
          ]
        }
      ],
      "source": [
        "# Stemming and Lemitizing (Back to root form)\n",
        "\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
        "print(stemmed_words)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(lemmatized_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4a6faf94",
      "metadata": {
        "id": "4a6faf94",
        "outputId": "86fd01dd-9eac-4214-e127-8f6416c5d3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.327, 'pos': 0.673, 'compound': 0.9237}\n"
          ]
        }
      ],
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "text = \"I love this course! This is very exciting and amazing!\"\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = sia.polarity_scores(text)\n",
        "print(sentiment_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "37d396df",
      "metadata": {
        "id": "37d396df",
        "outputId": "9d7b1264-34b7-47f7-ef7a-9c1b24b88deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.611, 'neu': 0.389, 'pos': 0.0, 'compound': -0.7813}\n"
          ]
        }
      ],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "text = \"I Hate this course! Its very hard and confusing\"\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = sia.polarity_scores(text)\n",
        "print(sentiment_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise:\n",
        "1. Take a paragraph\n",
        "2. Tokenize into sentences and words\n",
        "3. Remove stop words\n",
        "4. Perform stemming and Lemmatization, and print the outputs of both.\n",
        "5. Upload file or github link"
      ],
      "metadata": {
        "id": "h2cYAF0S_T5h"
      },
      "id": "h2cYAF0S_T5h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "text = \"Elizabeth, as they walked, observed, ‘It is a delightful thing, to be sure, to have a daughter well married.’ ‘But it is a matter of small consequence to her,’ said her father; ‘for at any rate, she cannot live with us. And so, the sooner she is married, the better. For if she should die, it would be a comfort to know that she had lived a happy life. But, my dear, I would not have you so ill-tempered as to not wish her well married as soon as possible.\"\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NybJ68k4_XJW",
        "outputId": "b147f9d5-5988-4c3a-da58-ce25f89d4169"
      },
      "id": "NybJ68k4_XJW",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Elizabeth', ',', 'as', 'they', 'walked', ',', 'observed', ',', '‘', 'It', 'is', 'a', 'delightful', 'thing', ',', 'to', 'be', 'sure', ',', 'to', 'have', 'a', 'daughter', 'well', 'married.', '’', '‘', 'But', 'it', 'is', 'a', 'matter', 'of', 'small', 'consequence', 'to', 'her', ',', '’', 'said', 'her', 'father', ';', '‘', 'for', 'at', 'any', 'rate', ',', 'she', 'can', 'not', 'live', 'with', 'us', '.', 'And', 'so', ',', 'the', 'sooner', 'she', 'is', 'married', ',', 'the', 'better', '.', 'For', 'if', 'she', 'should', 'die', ',', 'it', 'would', 'be', 'a', 'comfort', 'to', 'know', 'that', 'she', 'had', 'lived', 'a', 'happy', 'life', '.', 'But', ',', 'my', 'dear', ',', 'I', 'would', 'not', 'have', 'you', 'so', 'ill-tempered', 'as', 'to', 'not', 'wish', 'her', 'well', 'married', 'as', 'soon', 'as', 'possible', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Counter Tokens\n",
        "from collections import Counter\n",
        "\n",
        "word_counts = Counter(tokens)\n",
        "print(word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXXn2GiA_XXy",
        "outputId": "9efa6e82-fc3c-4125-cad5-892f431e18c8"
      },
      "id": "FXXn2GiA_XXy",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({',': 12, 'a': 5, 'to': 5, 'as': 4, 'she': 4, '.': 4, '‘': 3, 'is': 3, 'her': 3, 'not': 3, 'be': 2, 'have': 2, 'well': 2, '’': 2, 'But': 2, 'it': 2, 'so': 2, 'the': 2, 'married': 2, 'would': 2, 'Elizabeth': 1, 'they': 1, 'walked': 1, 'observed': 1, 'It': 1, 'delightful': 1, 'thing': 1, 'sure': 1, 'daughter': 1, 'married.': 1, 'matter': 1, 'of': 1, 'small': 1, 'consequence': 1, 'said': 1, 'father': 1, ';': 1, 'for': 1, 'at': 1, 'any': 1, 'rate': 1, 'can': 1, 'live': 1, 'with': 1, 'us': 1, 'And': 1, 'sooner': 1, 'better': 1, 'For': 1, 'if': 1, 'should': 1, 'die': 1, 'comfort': 1, 'know': 1, 'that': 1, 'had': 1, 'lived': 1, 'happy': 1, 'life': 1, 'my': 1, 'dear': 1, 'I': 1, 'you': 1, 'ill-tempered': 1, 'wish': 1, 'soon': 1, 'possible': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# StopWords (The, an , or ,etc.)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMPC_qvdAV74",
        "outputId": "bcc18542-4112-4c9a-9e6d-9cb1a5ec553f"
      },
      "id": "hMPC_qvdAV74",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Elizabeth', ',', 'walked', ',', 'observed', ',', '‘', 'delightful', 'thing', ',', 'sure', ',', 'daughter', 'well', 'married.', '’', '‘', 'matter', 'small', 'consequence', ',', '’', 'said', 'father', ';', '‘', 'rate', ',', 'live', 'us', '.', ',', 'sooner', 'married', ',', 'better', '.', 'die', ',', 'would', 'comfort', 'know', 'lived', 'happy', 'life', '.', ',', 'dear', ',', 'would', 'ill-tempered', 'wish', 'well', 'married', 'soon', 'possible', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming and Lemitizing (Back to root form)\n",
        "\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
        "print(stemmed_words)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6lhKUS1Adkc",
        "outputId": "4549e825-7fbb-4db7-a720-a92b1cb4a453"
      },
      "id": "H6lhKUS1Adkc",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['elizabeth', ',', 'as', 'they', 'walk', ',', 'observ', ',', '‘', 'it', 'is', 'a', 'delight', 'thing', ',', 'to', 'be', 'sure', ',', 'to', 'have', 'a', 'daughter', 'well', 'married.', '’', '‘', 'but', 'it', 'is', 'a', 'matter', 'of', 'small', 'consequ', 'to', 'her', ',', '’', 'said', 'her', 'father', ';', '‘', 'for', 'at', 'ani', 'rate', ',', 'she', 'can', 'not', 'live', 'with', 'us', '.', 'and', 'so', ',', 'the', 'sooner', 'she', 'is', 'marri', ',', 'the', 'better', '.', 'for', 'if', 'she', 'should', 'die', ',', 'it', 'would', 'be', 'a', 'comfort', 'to', 'know', 'that', 'she', 'had', 'live', 'a', 'happi', 'life', '.', 'but', ',', 'my', 'dear', ',', 'i', 'would', 'not', 'have', 'you', 'so', 'ill-temp', 'as', 'to', 'not', 'wish', 'her', 'well', 'marri', 'as', 'soon', 'as', 'possibl', '.']\n",
            "['Elizabeth', ',', 'a', 'they', 'walked', ',', 'observed', ',', '‘', 'It', 'is', 'a', 'delightful', 'thing', ',', 'to', 'be', 'sure', ',', 'to', 'have', 'a', 'daughter', 'well', 'married.', '’', '‘', 'But', 'it', 'is', 'a', 'matter', 'of', 'small', 'consequence', 'to', 'her', ',', '’', 'said', 'her', 'father', ';', '‘', 'for', 'at', 'any', 'rate', ',', 'she', 'can', 'not', 'live', 'with', 'u', '.', 'And', 'so', ',', 'the', 'sooner', 'she', 'is', 'married', ',', 'the', 'better', '.', 'For', 'if', 'she', 'should', 'die', ',', 'it', 'would', 'be', 'a', 'comfort', 'to', 'know', 'that', 'she', 'had', 'lived', 'a', 'happy', 'life', '.', 'But', ',', 'my', 'dear', ',', 'I', 'would', 'not', 'have', 'you', 'so', 'ill-tempered', 'a', 'to', 'not', 'wish', 'her', 'well', 'married', 'a', 'soon', 'a', 'possible', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPMntrqOAgJj"
      },
      "id": "BPMntrqOAgJj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bb2ca1a3",
      "metadata": {
        "id": "bb2ca1a3",
        "outputId": "7aeed4bf-2531-4ffd-869c-b042e1395a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive']\n"
          ]
        }
      ],
      "source": [
        "# Text Classification\n",
        "\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Training data\n",
        "documents = [\n",
        "    (\"I love this course\", \"positive\"),\n",
        "    (\"I hate this program\", \"negative\"),\n",
        "    (\"This was an awesome movie\", \"positive\"),\n",
        "    (\"The course was terrible\", \"negative\")\n",
        "]\n",
        "\n",
        "# Prepare features and labels\n",
        "vectorizer = CountVectorizer()\n",
        "features = vectorizer.fit_transform([doc[0] for doc in documents])\n",
        "labels = [doc[1] for doc in documents]\n",
        "\n",
        "# Train a classifier (Naive Bayes)\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(features, labels)\n",
        "\n",
        "# Test with a new example\n",
        "new_example = vectorizer.transform([\"I really enjoyed watching this film\"])\n",
        "prediction = classifier.predict(new_example)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCwwL4CKAfWm"
      },
      "id": "oCwwL4CKAfWm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ab0a6c7a",
      "metadata": {
        "id": "ab0a6c7a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}